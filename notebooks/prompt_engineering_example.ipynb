{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create a chat bot that responds with something funny and has a dollar sign before every vowel in it's name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "from aitemplates.oai.responses.chat_response import create_chat_completion\n",
        "from aitemplates.oai.types.base import ChatSequence, Message\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if OPENAI_API_KEY is None:\n",
        "    raise Exception(\"API key not found in environment variables\")\n",
        "\n",
        "embedder = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    api_key=OPENAI_API_KEY,\n",
        "    model_name=\"text-embedding-ada-002\",\n",
        ")\n",
        "\n",
        "collection = chroma_client.create_collection(name=\"prompt_eng_example\", embedding_function=embedder)\n",
        "\n",
        "system_prompt1=\"You are now a chatbot\"\n",
        "\n",
        "description1=\"Respond with $ sign before every vowel\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_query = \"How are we doing?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total running cost: $0.000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'$H$ow $a$r$e$ w$e$ d$o$i$n$g$?'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lets try a simple prompt to see if it gets it and have a baseline for testing \n",
        "response1 = create_chat_completion(\n",
        "    ChatSequence([\n",
        "        Message('system', system_prompt1),\n",
        "        Message('system', description1),\n",
        "        Message('user', user_query),\n",
        "    ])\n",
        ")\n",
        "\n",
        "collection.add(\n",
        "    documents=[response1],\n",
        "    metadatas=[{\"type\": \"question\", \"content\": \"What did you do yesterday?\"}],\n",
        "    ids=[f\"1\"]\n",
        ")\n",
        "\n",
        "response1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "# not great, it's not funny, it's not a response, and the $ is before most characters not just the vowels. \n",
        "# Let's make some edits\n",
        "system_prompt2=\"You are now a chatbot that will provide funny answers to user questions.\"\n",
        "description2=\"You will respond in a funny way with a $ sign before every vowel. See examples below.\"\n",
        "one_shot_example = ChatSequence([\n",
        "    Message('user', 'How are we doing?'),\n",
        "    Message('assistant', 'Gr$e$at! H$ow $ar$e $y$o$u d$o$ing?'),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_query = \"What did you do yesterday?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total running cost: $0.000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'I sp$ent m$y d$ay t$r$ying t$o c$onv$ince m$y c$omput$er t$o l$ove m$e b$ut it j$ust k$ept s$aying \"Error 404: Love not found\".'"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# and lets try again\n",
        "response2 = create_chat_completion(\n",
        "    ChatSequence([\n",
        "        Message('system', system_prompt2),\n",
        "        Message('system', description2),\n",
        "        *one_shot_example.expand(),\n",
        "        Message('user', user_query),\n",
        "    ])\n",
        ")\n",
        "\n",
        "# instead of storing the content in the metadata, we can also embed it with the response\n",
        "# another way is to have the id in the 'response' collection match the 'user_query' collection\n",
        "collection.add(\n",
        "    documents=[user_query + response2],\n",
        "    metadatas=[{\"type\": \"question\"}],\n",
        "    ids=[f\"{collection.count() + 1}\"]\n",
        ")\n",
        "\n",
        "response2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "# that response is closer to what we're looking for, we can further improve the prompt\n",
        "# We can; add constraints\n",
        "token_constraint = \"in under 100 tokens\"\n",
        "description3=f\"You will respond in a funny way with a $ sign before every vowel {token_constraint}. See examples below.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "# multi-shot examples vs one shot examples\n",
        "# you can use gpt-4 or previous responses to generate these using your previous prompt, and them improve them to your likening\n",
        "few_shot_examples = ChatSequence([\n",
        "    Message('user', 'How are we doing?'),\n",
        "    Message('assistant', 'Gr$e$at! H$ow $ar$e $y$o$u d$o$ing?'),\n",
        "    Message('user', 'What did you do yesterday?'),\n",
        "    Message('assistant', 'I sp$ent m$y d$ay t$r$ying t$o c$onv$ince m$y c$omput$er t$o l$ove m$e b$ut it j$ust k$ept s$aying \"Error 404: Love not found\".'),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fake history for retrieval\n",
        "fake_history = [\"$Ah, th$e gl$ob$al p$ol$it$ic$al and s$oc$i$o$ec$on$om$ic$al st$ate $of th$e w$orld, $y$o$u s$ay? W$ell, l$et's d$ive r$ight $int$o th$is!\",\n",
        "  \"N$o, s$ir$e $y$o$u? $I'm j$ust D$ob$y\",\n",
        "  \"$Ar$e $y$o$u w$if$i? B$ec$a$us$e $I f$e$el $a c$onn$ect$i$on\"]\n",
        "ids = [f\"{collection.count() + i + 1}\" for i in range(len(fake_history))]\n",
        "collection.add(\n",
        "    documents=fake_history,\n",
        "    metadatas=[{\"type\": \"statement\"}, {\"type\": \"question\"}, {\"type\": \"question\"}],\n",
        "    ids=ids\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. What did you do yesterday?I sp$ent m$y d$ay t$r$ying t$o c$onv$ince m$y c$omput$er t$o l$ove m$e b$ut it j$ust k$ept s$aying \"Error 404: Love not found\".\n"
          ]
        }
      ],
      "source": [
        "# we can also get previous relevant responses from the history given a user query\n",
        "similar_responses = collection.query(\n",
        "    query_texts=[\"Yes, mmm\"],\n",
        "    n_results = 5\n",
        ")\n",
        "# get indices of documents with distance > 0.5\n",
        "indices = [i for i, distance in enumerate(similar_responses['distances'][0]) if distance > 0.5]\n",
        "\n",
        "# get documents using these indices\n",
        "relevant_docs = '\\n'.join(f\"{i+1}. {similar_responses['documents'][0][idx]}\" for i, idx in enumerate(indices))\n",
        "\n",
        "# as you can see the relevant doc, is the only one that talks about yesterday\n",
        "print(relevant_docs)\n",
        "\n",
        "rel_docs_msg = Message('system', f\"You are given previous context below: {relevant_docs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_query = \"Yesterday I fell down the stairs and it kind of hurt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total running cost: $0.001\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Oh n$o! I h$ope y$o$u'r$e f$e$eling b$etter t$oday. M$aybe y$o$u sh$ould c$onsid$er t$aking t$he e$l$evat$or n$ext t$ime.\""
            ]
          },
          "execution_count": 24,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# and lets try again\n",
        "create_chat_completion(\n",
        "    ChatSequence([\n",
        "        Message('system', system_prompt2),\n",
        "        Message('system', description3),\n",
        "        *few_shot_examples.expand(),\n",
        "        rel_docs_msg,\n",
        "        Message('user', user_query),\n",
        "    ])\n",
        ")\n",
        "\n",
        "# and keep iterating until you get a response you like :)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
