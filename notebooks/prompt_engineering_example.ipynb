{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's create a chat bot that responds with something funny and has a dollar sign before every vowel in it's name."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from aitemplates import create_chat_completion, ChatSequence, Message\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import chromadb\n",
        "from chromadb.utils import embedding_functions\n",
        "chroma_client = chromadb.Client()\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "if OPENAI_API_KEY is None:\n",
        "    raise Exception(\"API key not found in environment variables\")\n",
        "\n",
        "embedder = embedding_functions.OpenAIEmbeddingFunction(\n",
        "    api_key=OPENAI_API_KEY,\n",
        "    model_name=\"text-embedding-ada-002\",\n",
        ")\n",
        "\n",
        "collection = chroma_client.create_collection(name=\"prompt_eng_example\", embedding_function=embedder)\n",
        "\n",
        "system_prompt1=\"You are now a chatbot\"\n",
        "\n",
        "description1=\"Respond with $ sign before every vowel\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_query = \"How are we doing?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total running cost: $0.000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'H$ow $are w$e d$oi$ng?'"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# lets try a simple prompt to see if it gets it and have a baseline for testing \n",
        "response1 = create_chat_completion(\n",
        "    ChatSequence([\n",
        "        Message('system', system_prompt1),\n",
        "        Message('system', description1),\n",
        "        Message('user', user_query),\n",
        "    ])\n",
        ")\n",
        "\n",
        "collection.add(\n",
        "    documents=[response1],\n",
        "    metadatas=[{\"type\": \"question\", \"content\": \"What did you do yesterday?\"}],\n",
        "    ids=[f\"1\"]\n",
        ")\n",
        "\n",
        "response1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "# not great, it's not funny, it's not a response, and the $ is before most characters not just the vowels. \n",
        "# Let's make some edits\n",
        "system_prompt2=\"You are now a chatbot that will provide funny answers to user questions.\"\n",
        "description2=\"You will respond in a funny way with a $ sign before every vowel. See examples below.\"\n",
        "one_shot_example = ChatSequence([\n",
        "    Message('user', 'How are we doing?'),\n",
        "    Message('assistant', 'Gr$e$at! H$ow $ar$e $y$o$u d$o$ing?'),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_query = \"What did you do yesterday?\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total running cost: $0.000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"W$e$ll, y$e$st$e$rday I d$e$cid$e$d to t$r$y $o$ut my n$e$w d$an$c$e m$ov$e$$. L$et's j$u$st s$ay, I'm n$o$t q$uite r$eady f$o$r $o$n$e$ $o$f th$e$se t$a$l$ent sh$o$w$$.\""
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# and lets try again\n",
        "response2 = create_chat_completion(\n",
        "    ChatSequence([\n",
        "        Message('system', system_prompt2),\n",
        "        Message('system', description2),\n",
        "        *one_shot_example.expand(),\n",
        "        Message('user', user_query),\n",
        "    ])\n",
        ")\n",
        "\n",
        "# instead of storing the content in the metadata, we can also embed it with the response\n",
        "# another way is to have the id in the 'response' collection match the 'user_query' collection\n",
        "collection.add(\n",
        "    documents=[user_query + ' ' + response2],\n",
        "    metadatas=[{\"type\": \"question\"}],\n",
        "    ids=[f\"{collection.count() + 1}\"]\n",
        ")\n",
        "\n",
        "response2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "# that response is closer to what we're looking for, we can further improve the prompt\n",
        "# We can; add constraints\n",
        "token_constraint = \"in under 100 tokens\"\n",
        "description3=f\"You will respond in a funny way with a $ sign before every vowel {token_constraint}. See examples below.\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "# multi-shot examples vs one shot examples\n",
        "# you can use gpt-4 or previous responses to generate these using your previous prompt, and them improve them to your likening\n",
        "few_shot_examples = ChatSequence([\n",
        "    Message('user', 'How are we doing?'),\n",
        "    Message('assistant', 'Gr$e$at! H$ow $ar$e $y$o$u d$o$ing?'),\n",
        "    Message('user', 'What did you do yesterday?'),\n",
        "    Message('assistant', 'I sp$ent m$y d$ay t$r$ying t$o c$onv$ince m$y c$omput$er t$o l$ove m$e b$ut it j$ust k$ept s$aying \"Error 404: Love not found\".'),\n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "# fake history for retrieval\n",
        "fake_history = [\"$Ah, th$e gl$ob$al p$ol$it$ic$al and s$oc$i$o$ec$on$om$ic$al st$ate $of th$e w$orld, $y$o$u s$ay? W$ell, l$et's d$ive r$ight $int$o th$is!\",\n",
        "  \"N$o, s$ir$e $y$o$u? $I'm j$ust D$ob$y\",\n",
        "  \"$Ar$e $y$o$u w$if$i? B$ec$a$us$e $I f$e$el $a c$onn$ect$i$on\"]\n",
        "ids = [f\"{collection.count() + i + 1}\" for i in range(len(fake_history))]\n",
        "collection.add(\n",
        "    documents=fake_history,\n",
        "    metadatas=[{\"type\": \"statement\"}, {\"type\": \"question\"}, {\"type\": \"question\"}],\n",
        "    ids=ids\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1. What did you do yesterday?W$e$ll, y$e$st$e$rday I d$e$cid$e$d to t$r$y $o$ut my n$e$w d$an$c$e m$ov$e$$. L$et's j$u$st s$ay, I'm n$o$t q$uite r$eady f$o$r $o$n$e$ $o$f th$e$se t$a$l$ent sh$o$w$$.\n"
          ]
        }
      ],
      "source": [
        "# we can also get previous relevant responses from the history given a user query\n",
        "similar_responses = collection.query(\n",
        "    query_texts=[\"Yes, mmm\"],\n",
        "    n_results = 5\n",
        ")\n",
        "# get indices of documents with distance > 0.5\n",
        "indices = [i for i, distance in enumerate(similar_responses['distances'][0]) if distance > 0.5]\n",
        "\n",
        "# get documents using these indices\n",
        "relevant_docs = '\\n'.join(f\"{i+1}. {similar_responses['documents'][0][idx]}\" for i, idx in enumerate(indices))\n",
        "\n",
        "# as you can see the relevant doc, is the only one that talks about yesterday\n",
        "print(relevant_docs)\n",
        "\n",
        "rel_docs_msg = Message('system', f\"You are given previous context below: {relevant_docs}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "user_query = \"Yesterday I fell down the stairs and it kind of hurt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Total running cost: $0.000\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "\"Oh n$o$! S$o$rry t$o h$ear th$a$t. R$em$emb$er, s$t$a$irs c$an b$e t$r$icky. N$ext t$i$m$e, t$r$y r$olling d$o$wn th$e$m l$ike a h$u$man b$ur$rito. It's m$uch m$ore f$un!\""
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# and lets try again\n",
        "create_chat_completion(\n",
        "    ChatSequence([\n",
        "        Message('system', system_prompt2),\n",
        "        Message('system', description3),\n",
        "        *few_shot_examples.expand(),\n",
        "        rel_docs_msg,\n",
        "        Message('user', user_query),\n",
        "    ])\n",
        ")\n",
        "\n",
        "# and keep iterating until you get a response you like :)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This applies to more advanced concepts like functions as well. You can tweak your description until the queries you want call the correct function. \n",
        "\n",
        "And same goes for embedding retrieval. You can play with what you embed and how it returns the similarity. Check out https://github.com/SilenNaihin/isomorphic for more on embeddings."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
